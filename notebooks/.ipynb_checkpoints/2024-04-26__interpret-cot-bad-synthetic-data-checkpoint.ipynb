{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1e30b8c-18ae-4066-b00b-c5f7ae3e5a49",
   "metadata": {},
   "source": [
    "# Goals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9ffcac-b085-40ca-99d9-56e4dbe38589",
   "metadata": {},
   "source": [
    "Following a similar theme as prior notebooks, this notebook ALSO manually inspects how good the BAD synthetic data is.\n",
    "\n",
    "This notebook has a similar structure to the other notebooks. First, we download data from the remote server, where I run both open-source models and closed-source models. Then:\n",
    "\n",
    "1. I manually inspect data generated from the Chicago Manual of Style\n",
    "2. I manually inspect data generated from other style-guides (e.g. Buzzfeed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b23a0cd-2012-4f26-9ade-52373cfb1e23",
   "metadata": {},
   "source": [
    "# Download the Data from the server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "796958ff-dade-4120-9fe8-f873cb677c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "97650525-6b13-45e6-a4a5-9c363f09c45a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/project/jonmay_231/spangher/Projects/style-guides/tasks/generate_synthetic_example_data/buzzfeed__command-r_zeroshot_cot_bad_only.jsonl\n",
      "/project/jonmay_231/spangher/Projects/style-guides/tasks/generate_synthetic_example_data/buzzfeed__gpt-4-turbo_zeroshot_cot_bad_only.jsonl\n",
      "/project/jonmay_231/spangher/Projects/style-guides/tasks/generate_synthetic_example_data/buzzfeed__llama-3-70b_zeroshot_cot_bad_only.jsonl\n",
      "/project/jonmay_231/spangher/Projects/style-guides/tasks/generate_synthetic_example_data/command-r_zeroshot_cot_bad_only.jsonl\n",
      "/project/jonmay_231/spangher/Projects/style-guides/tasks/generate_synthetic_example_data/gpt-3.5-turbo_zeroshot_cot_bad_only.jsonl\n",
      "/project/jonmay_231/spangher/Projects/style-guides/tasks/generate_synthetic_example_data/gpt-4-turbo_zeroshot_cot_bad_only.jsonl\n",
      "/project/jonmay_231/spangher/Projects/style-guides/tasks/generate_synthetic_example_data/guardian__command-r_zeroshot_cot_bad_only.jsonl\n",
      "/project/jonmay_231/spangher/Projects/style-guides/tasks/generate_synthetic_example_data/guardian__gpt-4-turbo_zeroshot_cot_bad_only.jsonl\n",
      "/project/jonmay_231/spangher/Projects/style-guides/tasks/generate_synthetic_example_data/guardian__llama-3-70b_zeroshot_cot_bad_only.jsonl\n",
      "/project/jonmay_231/spangher/Projects/style-guides/tasks/generate_synthetic_example_data/llama-3-70b_zeroshot_cot_bad_only.jsonl\n",
      "/project/jonmay_231/spangher/Projects/style-guides/tasks/generate_synthetic_example_data/mixtral_zeroshot_cot_bad_only.jsonl\n",
      "/project/jonmay_231/spangher/Projects/style-guides/tasks/generate_synthetic_example_data/mother_jones__command-r_zeroshot_cot_bad_only.jsonl\n",
      "/project/jonmay_231/spangher/Projects/style-guides/tasks/generate_synthetic_example_data/mother_jones__gpt-4-turbo_zeroshot_cot_bad_only.jsonl\n",
      "/project/jonmay_231/spangher/Projects/style-guides/tasks/generate_synthetic_example_data/mother_jones__llama-3-70b_zeroshot_cot_bad_only.jsonl\n"
     ]
    }
   ],
   "source": [
    "proj_dir = \"/project/jonmay_231/spangher/Projects/style-guides/tasks/generate_synthetic_example_data\"\n",
    "local_data_dir = \"../tasks/generate_synthetic_example_data/output_data/chicago_only\"\n",
    "! ssh end \"ls $proj_dir/*cot_bad*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "fb98f5ff-8bee-44f3-b272-cf8759260a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buzzfeed__command-r_zeroshot_cot_bad_only.jso 100% 1599KB   1.4MB/s   00:01    \n",
      "buzzfeed__gpt-4-turbo_zeroshot_cot_bad_only.j 100% 1883KB   1.7MB/s   00:01    \n",
      "buzzfeed__llama-3-70b_zeroshot_cot_bad_only.j 100% 1676KB   2.2MB/s   00:00    \n",
      "command-r_zeroshot_cot_bad_only.jsonl         100% 3966KB   4.2MB/s   00:00    \n",
      "gpt-3.5-turbo_zeroshot_cot_bad_only.jsonl     100% 1361KB   4.3MB/s   00:00    \n",
      "gpt-4-turbo_zeroshot_cot_bad_only.jsonl       100% 2204KB   4.0MB/s   00:00    \n",
      "guardian__command-r_zeroshot_cot_bad_only.jso 100% 4568KB   4.7MB/s   00:00    \n",
      "guardian__gpt-4-turbo_zeroshot_cot_bad_only.j 100% 7792KB   6.0MB/s   00:01    \n",
      "guardian__llama-3-70b_zeroshot_cot_bad_only.j 100% 2034KB   5.8MB/s   00:00    \n",
      "llama-3-70b_zeroshot_cot_bad_only.jsonl       100% 4427KB   6.1MB/s   00:00    \n",
      "mixtral_zeroshot_cot_bad_only.jsonl           100% 2133KB   4.2MB/s   00:00    \n",
      "mother_jones__command-r_zeroshot_cot_bad_only 100%  426KB   4.1MB/s   00:00    \n",
      "mother_jones__gpt-4-turbo_zeroshot_cot_bad_on 100%  476KB   1.2MB/s   00:00    \n",
      "mother_jones__llama-3-70b_zeroshot_cot_bad_on 100%  496KB   1.2MB/s   00:00    \n"
     ]
    }
   ],
   "source": [
    "! scp end:\"$proj_dir/*cot_bad*\" $local_data_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09803121-decf-456b-8a45-dd18f190eb94",
   "metadata": {},
   "source": [
    "# Read in Chicago-Only Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "45eea042-70fa-4ca0-ae05-672d45bfe4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd \n",
    "\n",
    "orig_input_file = pd.read_json('../corpora/chicago-style-guide/all-rules.jsonl', lines=True)\n",
    "bad_sentence_files = glob.glob(local_data_dir + '/*cot*')\n",
    "\n",
    "mixtral_data_df = pd.read_json(local_data_dir + '/mixtral_zeroshot_cot_bad_only.jsonl', lines=True)\n",
    "gpt4_data_df = pd.read_json(local_data_dir + '/gpt-4-turbo_zeroshot_cot_bad_only.jsonl', lines=True)\n",
    "llama_data_df = pd.read_json(local_data_dir + '/llama-3-70b_zeroshot_cot_bad_only.jsonl', lines=True)\n",
    "gpt3_data_df = pd.read_json(local_data_dir + '/gpt-3.5-turbo_zeroshot_cot_bad_only.jsonl', lines=True)\n",
    "command_r_data_df = pd.read_json(local_data_dir + '/command-r_zeroshot_cot_bad_only.jsonl', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d27cb06-d84f-4b80-896b-6240addccf76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "idx = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "79b98c0e-486a-4f34-be31-cdff7bd39d66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_data_df_w_all_annotations = (\n",
    "    orig_input_file\n",
    "    ## gpt 4\n",
    "         .merge(gpt4_data_df\n",
    "                # .drop(columns=['message'])\n",
    "                .rename(columns={'key': 'url'}))\n",
    "         # .assign(was_unclear_gpt4=lambda df: df['parsed_output'] == WAS_UNCLEAR_STR)\n",
    "         # .assign(parsed_output=lambda df: df['parsed_output'].apply(lambda x: x if x != WAS_UNCLEAR_STR else None))\n",
    "         # .rename(columns={'parsed_output': 'parsed_gpt4'})\n",
    "         .rename(columns={'message': 'message_gpt4'})\n",
    "    # ##  mixtral\n",
    "         .merge(mixtral_data_df\n",
    "                    # .drop(columns=['message'])\n",
    "                    .rename(columns={'key': 'url'}), how='left')\n",
    "         # .assign(was_unclear_mixtral=lambda df: df['parsed_output'] == WAS_UNCLEAR_STR)\n",
    "         # .assign(parsed_output=lambda df: df['parsed_output'].apply(lambda x: x if x != WAS_UNCLEAR_STR else None))\n",
    "         # .rename(columns={'parsed_output': 'parsed_mixtral'})\n",
    "        .rename(columns={'message': 'message_mixtral'})\n",
    "    # ##  command-r\n",
    "         .merge(command_r_data_df\n",
    "                # .drop(columns=['message'])\n",
    "                .rename(columns={'key': 'url'}), how='left')\n",
    "         # .assign(was_unclear_command_r=lambda df: df['parsed_output'] == WAS_UNCLEAR_STR)\n",
    "         # .assign(parsed_output=lambda df: df['parsed_output'].apply(lambda x: x if x != WAS_UNCLEAR_STR else None))\n",
    "         # .rename(columns={'parsed_output': 'parsed_command_r'})\n",
    "         .rename(columns={'message': 'message_command_r'})\n",
    "    # ##  llama 3\n",
    "         .merge(llama_data_df\n",
    "                    # .drop(columns=['message'])\n",
    "                    .rename(columns={'key': 'url'}), how='left')\n",
    "         # .assign(was_unclear_llama=lambda df: df['parsed_output'] == WAS_UNCLEAR_STR)\n",
    "         # .assign(parsed_output=lambda df: df['parsed_output'].apply(lambda x: x if x != WAS_UNCLEAR_STR else None))\n",
    "         # .rename(columns={'parsed_output': 'parsed_command_llama'})    \n",
    "         .rename(columns={'message': 'message_llama'})\n",
    "        .drop_duplicates('url')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "04e2e565-d29a-422b-91d5-41e07931c6b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content\n",
      "---------------------------------\n",
      "Large or complex fractions are expressed as numeric decimal fractions (cf. 9.14). When a quantity equals less than 1.00, a zero normally appears before the decimal point as an aid to readability, particularly in scientific contexts and especially if quantities greater than 1.00 appear in the same context. Note that a unit of measure with a quantity of less than one is generally treated as if it were plural (see 10.65, 10.53). See also 9.55, 9.58.\n",
      "\n",
      "a mean of 0.73\n",
      "the ratio 0.85\n",
      "In Cyprus, there were 0.96 females for every male in the general population; in the sixty-five-and-over age group, the number was 1.30.\n",
      "\n",
      "In contexts where decimal quantities must be 1.00 or less, as in probabilities, batting averages, and the like, or between −1.00 and 1.00, as in correlation coefficients, a zero is typically omitted before the decimal point. For zeros with decimal points in tables, see 3.72.\n",
      "\n",
      "\n",
      "p < .05\n",
      "\n",
      "R = .10\n",
      "Ty Cobb’s career batting average was .367.\n",
      "\n",
      "By a similar token, the zero is routinely omitted from firearm calibers expressed as fractions of an inch.\n",
      "\n",
      "They found and confiscated a .38 police special and a .22-caliber single-shot rifle.\n",
      "\n",
      "\n",
      "message_gpt4\n",
      "---------------------------------\n",
      "1. **Is there a rule being expressed?**  \n",
      "   Yes, the style guide expresses specific rules regarding the use of zeros before decimal points in different contexts.\n",
      "\n",
      "2. **Is this rule something that can be violated?**  \n",
      "   Yes, the rules can be violated by not following the specified formatting for decimal numbers.\n",
      "\n",
      "3. **Simplify the rule in plain language and specify ways it can be broken.**  \n",
      "   The rule states:\n",
      "   - Include a zero before decimal fractions less than 1.00 for clarity, especially in scientific contexts or when numbers greater than 1.00 are also present.\n",
      "   - Omit the zero before decimal fractions in specific contexts like probabilities, batting averages, correlation coefficients, and firearm calibers.\n",
      "\n",
      "   Ways to break this rule:\n",
      "   - Omitting the zero before decimal fractions less than 1.00 in general contexts.\n",
      "   - Including a zero before decimal fractions in contexts where it should be omitted (probabilities, batting averages, etc.).\n",
      "\n",
      "Here are 10 example sentences that violate this rule:\n",
      "\n",
      "```python\n",
      "[\n",
      "    \"The recent study shows that water boils at .100 degrees Celsius under certain conditions.\",\n",
      "    \"In the latest survey, only .55 of respondents agreed with the new policy.\",\n",
      "    \"The probability of rain tomorrow is 0.2 according to the weather forecast.\",\n",
      "    \"His batting average this season is 0.456, which is one of the highest in the league.\",\n",
      "    \"The correlation between the variables was found to be 0.05, indicating a very weak relationship.\",\n",
      "    \"The new report states that .75 of the population supports the change in law.\",\n",
      "    \"During the experiment, the solution had a pH level of .07.\",\n",
      "    \"The economist noted that the growth rate of the economy was .03 last quarter.\",\n",
      "    \"She scored .95 on her final exam, which was the highest in the class.\",\n",
      "    \"The museum reported that .85 of all visitors were satisfied with their experience.\"\n",
      "]\n",
      "```\n",
      "\n",
      "These sentences either incorrectly omit or include the zero in decimal fractions, contrary to the guidelines specified in the style guide entry.\n",
      "\n",
      "\n",
      "message_mixtral\n",
      "---------------------------------\n",
      "No clear rule or preference expressed. The entry provides a guideline for expressing decimal fractions and the use of the zero, but it does not explicitly state that the provided examples must be followed, nor does it specify a penalty for not following them. Therefore, it is not a rule that can be violated. Instead, it is a style recommendation.\n",
      "\n",
      "However, if we simplify the guideline in plain language, it would be: \"When expressing decimal fractions, include a zero before the decimal point if the quantity is less than 1.00, except in certain contexts such as probabilities, batting averages, and firearm calibers.\"\n",
      "\n",
      "Here are 10 example sentences that violate this guideline by not including a zero before the decimal point when the quantity is less than 1.00:\n",
      "\n",
      "[\n",
      "\"The company's market share dropped to .5% last quarter.\",\n",
      "\"The unemployment rate in the region is currently .32.\",\n",
      "\"The new policy will affect approximately .75% of our customers.\",\n",
      "\"The test showed a radiation level of .08 mSv.\",\n",
      "\"The patient's white blood cell count is .9.\",\n",
      "\"The new product has a failure rate of .02.\",\n",
      "\"The company's revenue growth was -.15% last year.\",\n",
      "\"The new policy will save the company .03% in operating costs.\",\n",
      "\"The new product has a defect rate of .005.\",\n",
      "\"The new policy will reduce emissions by .01%.\"\n",
      "]</s>\n",
      "\n",
      "\n",
      "message_command_r\n",
      "---------------------------------\n",
      "1. Yes, there is a clear rule being expressed. It regards how to format certain decimal numbers.\n",
      "\n",
      "2. Yes, this rule can be violated, as evidenced by the examples given.\n",
      "\n",
      "3. The general rule, as understood through context and the examples given, is that decimals less than 1.00 should have a leading zero in most circumstances. \n",
      "\n",
      "This rule can be broken in the following ways:\n",
      "- When the decimal number is already specified in a unit of measurement, such as in lengths or calibers.\n",
      "- When the number is meant to be understood as a probability, correlation coefficient, or similar metric where the full range is 1.00 or less, or −1.00 to 1.00.\n",
      "\n",
      "Here are 10 example sentences that violate the stated rule:\n",
      "\n",
      "1. The study found that the average household size had decreased to 2.4 over the past year.\n",
      "\n",
      "2. Health officials reported 29 new COVID cases, with an average age of 37.\n",
      "\n",
      "3. The poll shows a 46% approval rating, a 7-point drop from the previous month.\n",
      "\n",
      "4. NASA's latest Mars orbit insertion maneuver succeeded, with the spacecraft's engine firing for a crucial 28-minute window.\n",
      "\n",
      "5. Apple's new iPhone release has a sleek new design and boasts a 12MP camera, a major upgrade.\n",
      "\n",
      "6. The correlation between social media use and anxiety disorders, a growing concern, showed a weak but significant positive correlation of 0.42.\n",
      "\n",
      "7. Police have identified a suspected gunman in the recent string of shootings, a 23-year-old male with a reported IQ of 78.\n",
      "\n",
      "8. Farmers in the region are struggling with crop yields, which have halved this season due to the ongoing drought.\n",
      "\n",
      "9. The new bridge construction is 86% complete, with progress on schedule.\n",
      "\n",
      "10. Omitted zeros can also be seen in firearm calibers, such as the popular .357 magnum.\n",
      "\n",
      "These examples violate the rule by either omitting the leading zero or including units of measurement alongside the decimal fractions.<|END_OF_TURN_TOKEN|>\n",
      "\n",
      "\n",
      "message_llama\n",
      "---------------------------------\n",
      "Let's break down the entry step-by-step.\n",
      "\n",
      "1. Is there a rule being expressed?\n",
      "Yes, the entry expresses rules about when to include or omit a zero before a decimal point in numeric decimal fractions.\n",
      "\n",
      "2. Is this rule something that can be violated?\n",
      "Yes, the rule can be violated by including or omitting the zero in situations where it's not recommended.\n",
      "\n",
      "Now, let's simplify the rule in plain language and specify ways it can be broken:\n",
      "\n",
      "The rule states that when expressing decimal fractions, a zero should normally appear before the decimal point if the quantity is less than 1.00, except in specific contexts such as probabilities, batting averages, and correlation coefficients, where the zero can be omitted.\n",
      "\n",
      "Ways to break this rule:\n",
      "\n",
      "* Omitting the zero before the decimal point in situations where it's recommended (e.g., in scientific contexts or when quantities greater than 1.00 appear in the same context).\n",
      "* Including the zero before the decimal point in situations where it's not recommended (e.g., in probabilities, batting averages, or correlation coefficients).\n",
      "\n",
      "Here are 10 example sentences that violate this rule:\n",
      "\n",
      "```\n",
      "examples = [\n",
      "    \"The new policy has a probability of.5 of being approved.\",  # Should be 0.5\n",
      "    \"The team's batting average was.42 last season.\",  # Should be 0.42\n",
      "    \"The correlation coefficient was.87, indicating a strong relationship.\",  # Should be 0.87\n",
      "    \"The ratio of males to females in the population was 1. females for every.9 males.\",  # Should be 0.9\n",
      "    \"The company's stock price dropped by.5 points yesterday.\",  # Should be 0.5\n",
      "    \"The study found a significant correlation of.7 between the two variables.\",  # Should be 0.7\n",
      "    \"The athlete's career batting average was.321, a new record.\",  # Should be 0.321\n",
      "    \"The probability of winning the lottery is.00001.\",  # Should be 0.00001\n",
      "    \"The firearm caliber was.45 inches, a rare size.\",  # Should be.45 (but actually, it's an exception to the rule)\n",
      "    \"The researcher found a correlation coefficient of.95, indicating a strong relationship.\",  # Should be 0.95\n",
      "]\n",
      "```\n",
      "\n",
      "Note that sentence 9 is actually an exception to the rule, as the zero is omitted before the decimal point in firearm calibers expressed as fractions of an inch.<|eot_id|>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "d = (input_data_df_w_all_annotations\n",
    "     [['content', 'message_gpt4', 'message_mixtral', 'message_command_r', 'message_llama']]\n",
    "     .iloc[700]\n",
    "     # .iloc[0]\n",
    "     .to_dict()\n",
    ")\n",
    "\n",
    "for k, v in d.items():\n",
    "    print(k)\n",
    "    print('---------------------------------')\n",
    "    print(v)\n",
    "\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202d594b-17e5-412d-a9d4-6a73477f11f6",
   "metadata": {},
   "source": [
    "# Read in the Data from other Style Guides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "48770699-41b0-4813-b24b-5a68c4c465fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd \n",
    "\n",
    "orig_input_file = pd.read_csv('../corpora/mother_jones/parsed_rules.csv', index_col=0)\n",
    "mother_jones_data_files = list(filter(lambda x: 'mother_jones' in x, bad_sentence_files))\n",
    "\n",
    "gpt4_data_df = pd.read_json(list(filter(lambda x: 'gpt-4' in x, mother_jones_data_files))[0], lines=True).assign(algo='gpt4')\n",
    "llama_data_df = pd.read_json(list(filter(lambda x: 'llama-3' in x, mother_jones_data_files))[0], lines=True).assign(algo='llama')\n",
    "command_r_data_df = pd.read_json(list(filter(lambda x: 'command-r' in x, mother_jones_data_files))[0], lines=True).assign(algo='command_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "a6dd87ff-2009-4f42-98bb-91b735574a59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>key</th>\n",
       "      <th>algo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1. Is there a rule being expressed? \\n   Yes, ...</td>\n",
       "      <td>mother_jones__0</td>\n",
       "      <td>gpt4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1. Is there a rule being expressed? \\n   Yes, ...</td>\n",
       "      <td>mother_jones__1</td>\n",
       "      <td>gpt4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message              key  algo\n",
       "0  1. Is there a rule being expressed? \\n   Yes, ...  mother_jones__0  gpt4\n",
       "1  1. Is there a rule being expressed? \\n   Yes, ...  mother_jones__1  gpt4"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt4_data_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "f6e1dd5a-d954-4a7f-b16e-d3dc49066a1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "full_mother_jones_data_df = (\n",
    "    orig_input_file\n",
    "        .assign(key=lambda df: 'mother_jones__' + df.reset_index()['index'].astype(str))\n",
    "        .merge(gpt4_data_df[['key','message']].rename(columns={'message': 'gpt4_message'}), on='key')\n",
    "        .merge(llama_data_df[['key','message']].rename(columns={'message': 'llama_message'}), on='key')    \n",
    "        .merge(command_r_data_df[['key','message']].rename(columns={'message': 'command_r_message'}), on='key')    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "0691113a-a82f-49e8-810c-e39aa3dff516",
   "metadata": {},
   "outputs": [],
   "source": [
    "algos_to_compare =['gpt4', 'llama']\n",
    "idx = 250\n",
    "row = full_mother_jones_data_df.iloc[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "cc269386-536e-4e9e-ae73-0e6f1b9af8f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results were barely in Tuesday night, but…\n",
      "\n",
      "-----------------------------------------\n",
      "gpt4\n",
      "\n",
      "1. Is there a rule being expressed?\n",
      "\n",
      "The entry provided from the style guide, \"Results were barely in Tuesday night, but…\", does not explicitly state a rule. It appears to be a fragment of a sentence likely used to illustrate a specific style or usage in the context of live blogs.\n",
      "\n",
      "2. Is this rule something that can be violated?\n",
      "\n",
      "Since no clear rule or specific grammatical/spelling preference is expressed in the fragment provided, it's challenging to determine a rule that can be explicitly violated.\n",
      "\n",
      "Conclusion: No clear rule or preference expressed.\n",
      "------------------------------\n",
      "llama\n",
      "\n",
      "Let's break it down step by step.\n",
      "\n",
      "1. Is there a rule being expressed?\n",
      "Yes, the rule appears to be related to formatting and punctuation in live blog updates.\n",
      "\n",
      "2. Is this rule something that can be violated?\n",
      "Yes, it's possible to violate this rule by not following the specified format.\n",
      "\n",
      "Now, let's simplify the rule and specify ways it can be broken:\n",
      "\n",
      "The rule is about formatting live blog updates with corrections or updates, specifically using the format \"Corrections, Updates -> live blogs -> [time]:\" followed by a brief statement.\n",
      "\n",
      "To violate this rule, one could use a different format, omit certain elements, or use incorrect punctuation.\n",
      "\n",
      "Here are 10 example sentences that violate this rule:\n",
      "\n",
      "```\n",
      "[\n",
      "    \"Results were barely in Tuesday night but we're still counting.\",\n",
      "    \"Live blog update 7:05pm ET Results were barely in Tuesday night but…\",\n",
      "    \"7:05 p.m. ET - Results were barely in Tuesday night but…\",\n",
      "    \"Corrections Results were barely in Tuesday night but…\",\n",
      "    \"Live blog: Results were barely in Tuesday night but…\",\n",
      "    \"Update 7:05 ET Results were barely in Tuesday night but…\",\n",
      "    \"Results were barely in Tuesday night but… 7:05 p.m. ET\",\n",
      "    \"Live blog update Results were barely in Tuesday night but…\",\n",
      "    \"7:05pm ET Results were barely in Tuesday night but…\",\n",
      "    \"Corrections, Updates Results were barely in Tuesday night but…\"\n",
      "]\n",
      "```<|eot_id|>\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(row['rule_text'])\n",
    "print()\n",
    "print('-----------------------------------------')\n",
    "for a in algos_to_compare:\n",
    "    print(a)\n",
    "    print()\n",
    "    print(row[f'{a}_message'])\n",
    "    print('------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "3965c878-d35a-4394-9975-50c4186f28b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rule_title           Capitalization, Punctuation, Grammar, General ...\n",
       "rule_hierarchy       Capitalization, Punctuation, Grammar, General ...\n",
       "rule_text            • Use serial commas: one, two, and three. • Us...\n",
       "key                                                   mother_jones__10\n",
       "gpt4_message         1. Yes, there is a rule being expressed in the...\n",
       "llama_message        Let's break down the entry step-by-step.\\n\\n1....\n",
       "command_r_message    Yes, there is a rule being expressed, and it c...\n",
       "Name: 10, dtype: object"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59be0572-6916-4437-bc32-90c423c67875",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a25547-bad8-48c8-acbe-40f1fa410353",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c1719a-37e8-4d16-9b28-5a9dea101cf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4097adcf-87ae-4d8a-a576-39235f0a6ded",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3154814-756a-4bbc-95c6-3703f3db59ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9766f6-c588-4a5a-b75d-0cef2459e955",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3c6e6a-fbd7-43b8-a7f3-258b152a6a6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a483790-afd6-4098-b1af-2a4732ec8838",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531e962a-aaeb-438c-8d2d-c83ab6048346",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45aa721-3d0a-472e-ac09-7d568e78dff9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
